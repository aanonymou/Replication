# Import all classification package
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
import numpy as np
import random
import os
import sys
import string
import inspect, re

from configs import *
from featureLoader_wdate import *
from common import *

#for reproducible experiments uncomment these lines
#random.seed(480509637)
#np.random.seed(480509637)

def holdout_bydate(model, trainfeatures, trainlabels, testfeatures, testlabels):
    predicted_labels=list()
    model.fit ( trainfeatures, trainlabels )

    for j in range(0, len(testlabels)):
        y_pred = model.predict( [testfeatures[j]] )
        predicted_labels.append ( y_pred )

    y_pred = predicted_labels
    print("Number of features used "+str(len(trainfeatures[0]))) 
    prec=precision_score(testlabels, y_pred, average='weighted')
    rec=recall_score(testlabels, y_pred, average='weighted')
    f1=f1_score(testlabels, y_pred, average='weighted')
    acc=accuracy_score( testlabels, y_pred )
    return (prec, rec, f1, acc)


def split(features, labels):
    lab2dates = {}
    for (app,date) in list(features.keys()):
        lab = labels[(app,date)]
        if lab not in list(lab2dates.keys()):
            lab2dates[lab] = []
        lab2dates[lab].append( date )

    testfeatures = {}
    testlabels = {}
    trainfeatures = {}
    trainlabels = {}

    for lab in list(lab2dates.keys()):
        alldates = lab2dates[lab]
        alldates.sort()
        pivot = alldates [ int(len(alldates)*7/10) ]
        print ("%s pivot=%s" % (lab, pivot))
        for (app,date) in list(features.keys()):
            key = (app,date)
            if labels[key] != lab: continue
            if date > pivot:
                testfeatures[key] = features [key]
                testlabels [key] = labels [key]
            else:
                trainfeatures[ key ] = features [ key ]
                trainlabels [key] = labels [key]
    print("%d samples for training, %d samples  held out will be used for testing" % (len (trainfeatures), 
                                                                                      len(testfeatures)), 
          file=sys.stdout)

    return trainfeatures, trainlabels, testfeatures, testlabels

if __name__=="__main__":
    datasets = [ \
            {"benign":["zoobenign2010", "zoobenign2011"], "malware":["vs2010","vs2011", "zoo2010", "zoo2011"]},
            {"benign":["zoobenign2012", "zoobenign2013"], "malware":["vs2012","vs2013", "zoo2012", "zoo2013"]},
            {"benign":["zoobenign2014", "zoobenign2015"], "malware":["vs2014","vs2015", "zoo2014", "zoo2015"]},
            {"benign":["zoobenign2016", "zoobenign2017"], "malware":["vs2016","more2017", "zoo2016", "zoo2017"]},
            ]

    g_binary = True
    path_feat = "features_droidcat_byfirstseen"

    for i in range(0, len(datasets)):
        datatag = 'mal_det1' if i==0 else ('mal_det2' if i==1 else ('mal_det3' if i==3 else 'mal_det4'))
        bf1, bl1 = {}, {}
        print ("work on %s ... " % ( datasets[i] ))
        for k in range(0, len(datasets[i]['benign'])):
            print ("----work on %s ... " % ( datasets[i]['benign'][k] ))
            (bf2, bl2) = loadBenignData(path_feat+"/"+datasets[i]['benign'][k])
            bf1.update(bf2)
            bl1.update(bl2)
        for k in range(0, len(datasets[i]['malware'])):
            print ("----work on %s ... " % ( datasets[i]['malware'][k] ))
            (mf1, ml1) = loadMalwareNoFamily(path_feat+"/"+datasets[i]['malware'][k])
            bf1.update (mf1)
            bl1.update (ml1)

        _trainfeatures, _trainlabels, _testfeatures, _testlabels = split(bf1, bl1)

        #ensure features vectors have same length
        (trainfeatures, trainlabels) = adapt (_trainfeatures, _trainlabels)
        (testfeatures, testlabels) = adapt (_testfeatures, _testlabels)

        models = (RandomForestClassifier(n_estimators = 128, random_state=0),)
        
        #select only 70 features
        fsets = (FSET_YYY,)

        labels = list()
        for item in trainlabels:
            labels.append(item)
        for item in testlabels:
            labels.append(item)

        l2c = malwareCatStat(labels)
        for lab in list(l2c.keys()):
            print ("%s\t%s" % (lab, l2c[lab]))
        print ("%d classes in total" % len(list(l2c.keys())))

        fh = sys.stdout

        model2ret={}
        for model in models:
            for fset in fsets:
                print('model ' +  str(type(model).__name__) + "\t" + "feature set " + FSET_NAMES[str(fset)], file=fh)
                roc_bydate(g_binary, 
                           models[0], 
                           selectFeatures( trainfeatures, fset ), 
                           trainlabels, 
                           selectFeatures( testfeatures, fset), 
                           testlabels, datatag)
                ret = holdout_bydate(model, 
                                     selectFeatures( trainfeatures, fset ), 
                                     trainlabels, 
                                     selectFeatures( testfeatures, fset), 
                                     testlabels)
                model2ret[str(model)+str(fset)] = ret

        tlabs=('precision_weighted', 'recall_weighted', 'F1_weighted', 'accuracy')

        for i in (0,1,2,3):
            print (tlabs[i])
            cols=list()
            for model in models:
                col=list()
                for fset in fsets:
                    ret = model2ret[str(model)+str(fset)]
                    col.append(ret[i])
                cols.append(col)
            for r in range(0,len(cols[0])):
                for c in range(0,len(cols)):
                    print ("%s\t" % cols[c][r])
        print("*"*90)
    fh.flush()
    fh.close()
    sys.exit(0)
